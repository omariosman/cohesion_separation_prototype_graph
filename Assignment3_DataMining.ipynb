{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3_DataMining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "9kTnMUILxGY5"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "\n",
        "mymatrix = np.loadtxt('k2')\n",
        "mymatrix = mymatrix.transpose()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cohesion_prototype_calculate(clusters_data, clusters_centroid):\n",
        "  WSS = 0\n",
        "  for i in range(len(clusters_data)):\n",
        "    cluster_data = clusters_data[i]\n",
        "    cluster_centroid = clusters_centroid[i]\n",
        "    cluster_cohesion_prototype_based = 0\n",
        "    for j in range(len(cluster_data)):\n",
        "      instance_vector = cluster_data.iloc[j].to_numpy()\n",
        "      dist = np.linalg.norm(instance_vector - cluster_centroid)\n",
        "      cluster_cohesion_prototype_based += dist\n",
        "    WSS += cluster_cohesion_prototype_based\n",
        "  return WSS"
      ],
      "metadata": {
        "id": "sUIuEashilrE"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separation_prototype_calculate(k, m, cluster_mean_all):\n",
        "  BSS = 0\n",
        "  for i in range(k):\n",
        "    centroid_numpy = cluster_mean_all[i]\n",
        "    dist = np.linalg.norm(m - centroid_numpy)\n",
        "    BSS = BSS + (k * dist)\n",
        "  return BSS"
      ],
      "metadata": {
        "id": "_ny6Os4jioWM"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def calculate_manhattan(v1, v2):\n",
        "    if (len(v1) != len(v2)):\n",
        "        raise Exception(\"The length is not equal\")\n",
        "    sum = 0\n",
        "    for i in range(len(v1)):\n",
        "        sum += abs(v1[i] - v2[i])\n",
        "    return sum\n",
        "\n",
        "def cohesion_graph(clusters_data):\n",
        "  total_dist = 0\n",
        "  for i in range(len(clusters_data)):\n",
        "    cluster_data = clusters_data[i]\n",
        "    dist_for_cluster = 0\n",
        "    for j in range(len(cluster_data)):\n",
        "      first_element = cluster_data.iloc[j].to_numpy()\n",
        "      dist_for_one_element = 0\n",
        "      for k in range(len(cluster_data)):\n",
        "        second_element = cluster_data.iloc[k].to_numpy()\n",
        "        dist_for_one_element += calculate_manhattan(first_element, second_element)\n",
        "        #dist_for_one_element += cdist(first_element, second_element, metric='cityblock')\n",
        "      dist_for_cluster += dist_for_one_element\n",
        "      dist_for_cluster = dist_for_cluster / 2\n",
        "    total_dist += dist_for_cluster\n",
        "  return total_dist"
      ],
      "metadata": {
        "id": "wIJExFFRirq2"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separation_graph(clusters_data):\n",
        "  main_sum = 0\n",
        "  for i in range(len(clusters_data)):\n",
        "    cluster_data = clusters_data[i]\n",
        "    for j in range(len(cluster_data)):\n",
        "      instance = cluster_data.iloc[j]\n",
        "      first = instance.to_numpy()\n",
        "      for k in range(len(clusters_data)):\n",
        "        if (k <= i):\n",
        "          continue\n",
        "        my_cluster = clusters_data[k]\n",
        "        sum = 0\n",
        "        for p in range(len(my_cluster)):\n",
        "          second = my_cluster.iloc[p].to_numpy()\n",
        "          sum += calculate_manhattan(first, second)\n",
        "        main_sum += sum \n",
        "  return main_sum\n"
      ],
      "metadata": {
        "id": "5VdL8Op7iw1o"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k=2\n",
        "data = pd.read_csv(\"heart_failure_clinical_records_dataset_with_two_clusters.csv\")\n",
        "del data[\"DEATH_EVENT\"]"
      ],
      "metadata": {
        "id": "0y_S79BpjIz7"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster1_data = data[data[\"cluster\"] == \"cluster1\"]\n",
        "del cluster1_data[\"cluster\"]\n",
        "\n",
        "cluster2_data = data[data[\"cluster\"] == \"cluster2\"]\n",
        "del cluster2_data[\"cluster\"]\n",
        "\n",
        "\n",
        "\n",
        "k2_clusters_data = []\n",
        "k2_clusters_data.append(cluster1_data)\n",
        "k2_clusters_data.append(cluster2_data)\n",
        "\n",
        "cluster1_mean_k2 = mymatrix[1]\n",
        "cluster2_mean_k2 = mymatrix[2]\n",
        "\n",
        "k2_clusters_centroid = []\n",
        "k2_clusters_centroid.append(cluster1_mean_k2)\n",
        "k2_clusters_centroid.append(cluster2_mean_k2)\n"
      ],
      "metadata": {
        "id": "Xjve-MvpjJVP"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k2 cohesion prototype\n",
        "k2_cohesion_prototype = cohesion_prototype_calculate(k2_clusters_data, k2_clusters_centroid)\n",
        "print(\"k2 cohesion prototype: \", k2_cohesion_prototype)\n",
        "\n",
        "#k2 cohesion graph\n",
        "k2_cohesion_graph = cohesion_graph(k2_clusters_data)\n",
        "print(\"k2 cohesion graph: \", k2_cohesion_graph)\n",
        "\n",
        "\n",
        "#k2 separation protoype\n",
        "k2_m_numpy = data.mean(axis=0).to_numpy()\n",
        "k2_separtion_prototype = separation_prototype_calculate(2,  k2_m_numpy, k2_clusters_data)\n",
        "print(\"k2 separation prototype:\", k2_separtion_prototype)\n",
        "\n",
        "#k2 separation graph\n",
        "k2_separation_graph = separation_graph(k2_clusters_data)\n",
        "print(\"k2 separation graph:\", k2_separation_graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNfzTwakjg_C",
        "outputId": "5417c86f-5363-40e2-9d1f-0ebcf9518bd0"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k2 cohesion prototype:  19991082.854808897\n",
            "k2 cohesion graph:  61036403.23362812\n",
            "k2 separation prototype: 4773060.226551099\n",
            "k2 separation graph: 2285599978.666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#k=3\n",
        "data = pd.read_csv(\"heart_failure_clinical_records_dataset_with_three_clusters.csv\")\n",
        "del data[\"DEATH_EVENT\"]\n"
      ],
      "metadata": {
        "id": "9nvwPYqOdmX1"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "cluster1_data = data[data[\"cluster\"] == \"cluster1\"]\n",
        "del cluster1_data[\"cluster\"]\n",
        "\n",
        "cluster2_data = data[data[\"cluster\"] == \"cluster2\"]\n",
        "del cluster2_data[\"cluster\"]\n",
        "\n",
        "cluster3_data = data[data[\"cluster\"] == \"cluster3\"]\n",
        "del cluster3_data[\"cluster\"]\n",
        "\n",
        "\n",
        "k3_clusters_data = []\n",
        "k3_clusters_data.append(cluster1_data)\n",
        "k3_clusters_data.append(cluster2_data)\n",
        "k3_clusters_data.append(cluster3_data)\n",
        "\n",
        "cluster1_mean_k3 = [59.2124, 0.2743, 606.6283, 0.1062, 40.1504, 0.3363, 260462.7996, 1.1984, 137.3363, 0.8319, 0.531, 159.3894] \n",
        "cluster2_mean_k3 = [66.2851, 0.4096, 683.6265, 0.3253, 33.2289, 0.3976, 256886.5096, 1.886, 135.5301, 0.747, 0.3614, 71.2771] \n",
        "cluster3_mean_k3 = [58.2201, 0.6214, 472.6214, 0.835, 39.7282, 0.3301, 271749.263, 1.2117, 136.7282, 0.3689, 0.0583, 145.835]\n",
        "\n",
        "k3_clusters_centroid = []\n",
        "k3_clusters_centroid.append(cluster1_mean_k3)\n",
        "k3_clusters_centroid.append(cluster2_mean_k3)\n",
        "k3_clusters_centroid.append(cluster3_mean_k3)\n",
        "\n"
      ],
      "metadata": {
        "id": "MuVQFUiMeNAS"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k3 cohesion prototype\n",
        "k3_cohesion_prototype = cohesion_prototype_calculate(k3_clusters_data, k3_clusters_centroid)\n",
        "print(\"k3 cohesion prototype: \", k3_cohesion_prototype)\n",
        "\n",
        "#k3 cohesion graph\n",
        "k3_cohesion_graph = cohesion_graph(k3_clusters_data)\n",
        "print(\"k3 cohesion graph: \", k3_cohesion_graph)\n",
        "\n",
        "\n",
        "#k3 separation protoype\n",
        "k3_m_numpy = data.mean(axis=0).to_numpy()\n",
        "k3_separtion_prototype = separation_prototype_calculate(3,  k3_m_numpy, k3_clusters_data)\n",
        "print(\"k3 separation prototype:\", k3_separtion_prototype)\n",
        "\n",
        "#k3 separation graph\n",
        "k3_separation_graph = separation_graph(k3_clusters_data)\n",
        "print(\"k3 separation graph:\", k3_separation_graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4BRJRHRfzis",
        "outputId": "eb3d5d8b-2cbe-4bff-fb52-5e9a402aa900"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k3 cohesion prototype:  20102517.02764405\n",
            "k3 cohesion graph:  49788753.23934552\n",
            "k3 separation prototype: 8765154.558204362\n",
            "k3 separation graph: 3030674193.625998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#k=4\n",
        "data = pd.read_csv(\"heart_failure_clinical_records_dataset_with_four_clusters.csv\")\n",
        "del data[\"DEATH_EVENT\"]"
      ],
      "metadata": {
        "id": "ZuWfZ2wWg9gB"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "cluster1_data = data[data[\"cluster\"] == \"cluster1\"]\n",
        "del cluster1_data[\"cluster\"]\n",
        "\n",
        "cluster2_data = data[data[\"cluster\"] == \"cluster2\"]\n",
        "del cluster2_data[\"cluster\"]\n",
        "\n",
        "cluster3_data = data[data[\"cluster\"] == \"cluster3\"]\n",
        "del cluster3_data[\"cluster\"]\n",
        "\n",
        "cluster4_data = data[data[\"cluster\"] == \"cluster4\"]\n",
        "del cluster4_data[\"cluster\"]\n",
        "\n",
        "cluster1_mean_k4 = [60.8592, 0.4507, 481.6197, 0.0, 40.8873, 0.4366, 258790.8194, 1.1859, 137.7042, 0.493, 0.0141, 154.1831] \n",
        "cluster2_mean_k4 = [66.5132, 0.4211, 666.5, 0.2632, 33.1316, 0.3947, 255471.8979, 1.8238, 135.5658, 0.7895, 0.3947, 68.2105]  \n",
        "cluster3_mean_k4 = [57.9004, 0.4943, 556.2069, 1.0, 39.3793, 0.3333, 274534.852, 1.3444, 136.2069, 0.3908, 0.0, 143.2644]       \n",
        "cluster4_mean_k4 = [57.9004, 0.4943, 556.2069, 1.0, 39.3793, 0.3333, 274534.852, 1.3444, 136.2069, 0.3908, 0.0, 143.2644] \n",
        "\n",
        "k4_clusters_data = []\n",
        "k4_clusters_data.append(cluster1_data)\n",
        "k4_clusters_data.append(cluster2_data)\n",
        "k4_clusters_data.append(cluster3_data)\n",
        "k4_clusters_data.append(cluster4_data)\n",
        "\n",
        "\n",
        "k4_clusters_centroid = []\n",
        "k4_clusters_centroid.append(cluster1_mean_k4)\n",
        "k4_clusters_centroid.append(cluster2_mean_k4)\n",
        "k4_clusters_centroid.append(cluster3_mean_k4)\n",
        "k4_clusters_centroid.append(cluster4_mean_k4)\n",
        "\n"
      ],
      "metadata": {
        "id": "3YZVQB44hB_v"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k4 cohesion prototype\n",
        "k4_cohesion_prototype = cohesion_prototype_calculate(k4_clusters_data, k4_clusters_centroid)\n",
        "print(\"k4 cohesion prototype: \", k4_cohesion_prototype)\n",
        "\n",
        "#k4 cohesion graph\n",
        "k4_cohesion_graph = cohesion_graph(k4_clusters_data)\n",
        "print(\"k4 cohesion graph: \", k4_cohesion_graph)\n",
        "\n",
        "\n",
        "#k4 separation protoype\n",
        "k4_m_numpy = data.mean(axis=0).to_numpy()\n",
        "k4_separtion_prototype = separation_prototype_calculate(3,  k4_m_numpy, k4_clusters_data)\n",
        "print(\"k4 separation prototype:\", k4_separtion_prototype)\n",
        "\n",
        "#k4 separation graph\n",
        "k4_separation_graph = separation_graph(k4_clusters_data)\n",
        "print(\"k4 separation graph:\", k4_separation_graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4psnbJ2hgxT",
        "outputId": "154f4c6d-72fa-4909-bd39-019972690aad"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k4 cohesion prototype:  20518039.73197378\n",
            "k4 cohesion graph:  50608037.85422426\n",
            "k4 separation prototype: 7107126.8690943895\n",
            "k4 separation graph: 3311467529.186\n"
          ]
        }
      ]
    }
  ]
}